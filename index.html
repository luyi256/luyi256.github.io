<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Lu Yi </title> <meta name="author" content="Lu Yi"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="Lu Yi's Homepage"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%91%E2%80%8D%F0%9F%8E%93&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://luyi256.github.io/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Lu Yi</span> </h1> <p class="desc">Renmin University of China, Beijing, China<br> Email: yilu@ruc.edu.cn<br> <a href="https://scholar.google.com/citations?user=xCFxaiYAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Google Scholar</a>    <a href="https://github.com/luyi256" rel="external nofollow noopener" target="_blank">GitHub</a> </p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/body_median-480.webp 480w,/assets/img/body_median-800.webp 800w,/assets/img/body_median-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/body_median.jpg?55eab01923952267cf6c657d9bba39b7" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="body_median.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I am currently a 3rd-year Ph.D. candidate at <a href="https://ai.ruc.edu.cn/en" rel="external nofollow noopener" target="_blank">Gaoling School of Artificial Intelligence</a>, <a href="https://en.ruc.edu.cn" rel="external nofollow noopener" target="_blank">Renmin University of China</a>, where I am fortunate to be advised by Prof. <a href="https://weizhewei.com/" rel="external nofollow noopener" target="_blank">Zhewei Wei</a>. Before my graduate studies, I received my B.E. degree in Computer Science and Technology at <a href="https://scs.bupt.edu.cn/" rel="external nofollow noopener" target="_blank">School of Computer Science</a>, Beijing University of Posts and Telecommunications in June 2022.</p> <p>My research interests lie in deep learning and data mining on graph data. In particular, I am interested in Dynamic Graph Neural Network, graph unlearning, and sub-linear time algorithms for large-scale graph analysis problem.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Feb 11, 2025</th> <td> Two papers, <a href="https://openreview.net/forum?id=pPyJyeLriR" rel="external nofollow noopener" target="_blank">ScaleGUN</a> and <a href="https://openreview.net/forum?id=8e2LirwiJT" rel="external nofollow noopener" target="_blank">TGB-Seq</a>, have been accepted by <a href="https://iclr.cc/Conferences/2025" rel="external nofollow noopener" target="_blank">ICLR2025</a>! ScaleGUN has been selected for a Spotlight presentation. A huge thanks to all my co-authors! You can check out the code for ScaleGUN <a href="https://github.com/luyi256/ScaleGUN" rel="external nofollow noopener" target="_blank">here</a> and the website for TGB-Seq <a href="https://tgb-seq.github.io/" rel="external nofollow noopener" target="_blank">here</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 15, 2024</th> <td> My co-first authored paper, “Random-Walk Probability Estimation on Dynamic Weighted Graphs”, has been accepted by <a href="https://crad.ict.ac.cn/" rel="external nofollow noopener" target="_blank">J-CRAD2024</a>. Many thanks to Hanzhi! Check out the <a href="https://crad.ict.ac.cn/article/doi/10.7544/issn1000-1239.202440148" rel="external nofollow noopener" target="_blank">paper</a> and <a href="https://github.com/luyi256/CoinFlipWalk" rel="external nofollow noopener" target="_blank">code</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 19, 2024</th> <td> One paper “A survey of dynamic graph neural networks” has been accepted by <a href="https://journal.hep.com.cn/fcs/EN/10.1007/s11704-024-3853-2" rel="external nofollow noopener" target="_blank">FCS2024</a>. Many thanks to Yanping! </td> </tr> <tr> <th scope="row" style="width: 20%">May 17, 2023</th> <td> One paper “Optimal Dynamic Subset Sampling: Theory and Applications” has been accepted by <a href="https://doi.org/10.1145/3580305.3599458" rel="external nofollow noopener" target="_blank">KDD2023</a>. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://iclr.cc/Conferences/2025/" rel="external nofollow noopener" target="_blank">ICLR 2025</a></abbr> </div> <div id="yi2024scalable" class="col-sm-8"> <div class="title"><a href="https://arxiv.org/pdf/2502.02975" rel="external nofollow noopener" target="_blank">Scalable and Certifiable Graph Unlearning: Overcoming the Approximation Error Barrier</a></div> <div class="author"> <em>Lu Yi</em>, and <a href="https://weizhewei.com" rel="external nofollow noopener" target="_blank">Zhewei Wei</a> </div> <div class="periodical"> <em>To be presented at ICLR 2025</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/ScaleGUN.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Graph unlearning has emerged as a pivotal research area for ensuring privacy protection, given the widespread adoption of Graph Neural Networks (GNNs) in applications involving sensitive user data. Among existing studies, certified graph unlearning is distinguished by providing robust privacy guarantees. However, current certified graph unlearning methods are impractical for large-scale graphs because they necessitate the costly re-computation of graph propagation for each unlearning request. Although numerous scalable techniques have been developed to accelerate graph propagation for GNNs, their integration into certified graph unlearning remains uncertain as these scalable approaches introduce approximation errors into node embeddings. In contrast, certified graph unlearning demands bounded model error on exact node embeddings to maintain its certified guarantee. To address this challenge, we present ScaleGUN, the first approach to scale certified graph unlearning to billion-edge graphs. ScaleGUN integrates the approximate graph propagation technique into certified graph unlearning, offering certified guarantees for three unlearning scenarios: node feature, edge and node unlearning. Extensive experiments on real-world datasets demonstrate the efficiency and unlearning efficacy of ScaleGUN. Remarkably, ScaleGUN accomplishes (ε,δ)=(1,10^-4) certified unlearning on the billion-edge graph ogbn-papers100M in 20 seconds for a 5,000 random edge removal request – of which only 5 seconds are required for updating the node embeddings – compared to 1.91 hours for retraining and 1.89 hours for re-propagation. Our code is available at https://github.com/luyi256/ScaleGUN.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://iclr.cc/Conferences/2025/" rel="external nofollow noopener" target="_blank">ICLR 2025</a></abbr> </div> <div id="yi2025tgb" class="col-sm-8"> <div class="title"><a href="https://arxiv.org/abs/2502.02975" rel="external nofollow noopener" target="_blank">TGB-Seq Benchmark: Challenging Temporal GNNs with Complex Sequential Dynamics</a></div> <div class="author"> <em>Lu Yi</em>, Jie Peng , Yanping Zheng , Fengran Mo , <a href="https://weizhewei.com" rel="external nofollow noopener" target="_blank">Zhewei Wei</a>, Yuhang Ye , Yue Zixuan , and Zengfeng Huang </div> <div class="periodical"> <em>To be presented at ICLR 2025</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/TGB-Seq.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Future link prediction is a fundamental challenge in various real-world dynamic systems. To address this, numerous temporal graph neural networks (temporal GNNs) and benchmark datasets have been developed. However, these datasets often feature excessive repeated edges and lack complex sequential dynamics, a key characteristic inherent in many real-world applications such as recommender systems and "Who-To-Follow" on social networks. This oversight has led existing methods to inadvertently downplay the importance of learning sequential dynamics, focusing primarily on predicting repeated edges. In this study, we demonstrate that existing methods, such as GraphMixer and DyGFormer, are inherently incapable of learning simple sequential dynamics, such as "a user who has followed OpenAI and Anthropic is more likely to follow AI at Meta next." Motivated by this issue, we introduce the Temporal Graph Benchmark with Sequential Dynamics (TGB-Seq), a new benchmark carefully curated to minimize repeated edges, challenging models to learn sequential dynamics and generalize to unseen edges. TGB-Seq comprises large real-world datasets spanning diverse domains, including e-commerce interactions, movie ratings, business reviews, social networks, citation networks and web link networks. Benchmarking experiments reveal that current methods usually suffer significant performance degradation and incur substantial training costs on TGB-Seq, posing new challenges and opportunities for future research. TGB-Seq datasets, leaderboards, and example codes are available at https://tgb-seq.github.io/.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://journal.hep.com.cn/fcs/EN/2095-2228/home.shtml" rel="external nofollow noopener" target="_blank">FCS 2024</a></abbr> </div> <div id="zheng2024survey" class="col-sm-8"> <div class="title"><a href="https://journal.hep.com.cn/fcs/EN/10.1007/s11704-024-3853-2" rel="external nofollow noopener" target="_blank">A Survey of Dynamic Graph Neural Networks</a></div> <div class="author"> Yanping Zheng , <em>Lu Yi</em>, and <a href="https://weizhewei.com" rel="external nofollow noopener" target="_blank">Zhewei Wei</a> </div> <div class="periodical"> <em>Frontiers of Computer Science</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/DGNNsurvey.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Graph neural networks (GNNs) have emerged as a powerful tool for effectively mining and learning from graph-structured data, with applications spanning numerous domains. However, most research focuses on static graphs, neglecting the dynamic nature of real-world networks where topologies and attributes evolve over time. By integrating sequence modeling modules into traditional GNN architectures, dynamic GNNs aim to bridge this gap, capturing the inherent temporal dependencies of dynamic graphs for a more authentic depiction of complex networks. This paper provides a comprehensive review of the fundamental concepts, key techniques, and state-of-the-art dynamic GNN models. We present the mainstream dynamic GNN models in detail and categorize models based on how temporal information is incorporated. We also discuss large-scale dynamic GNNs and pre-training techniques. Although dynamic GNNs have shown superior performance, challenges remain in scalability, handling heterogeneous information, and lack of diverse graph datasets. The paper also discusses possible future directions, such as adaptive and memory-enhanced models, inductive learning, and theoretical analysis. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge"><a href="https://kdd.org/kdd2023/" rel="external nofollow noopener" target="_blank">KDD 2023</a></abbr> </div> <div id="10.1145/3580305.3599458" class="col-sm-8"> <div class="title"><a href="https://doi.org/10.1145/3580305.3599458" rel="external nofollow noopener" target="_blank">Optimal Dynamic Subset Sampling: Theory and Applications</a></div> <div class="author"> <em>Lu Yi</em>, <a href="https://wanghzccls.github.io" rel="external nofollow noopener" target="_blank">Hanzhi Wang</a>, and <a href="https://weizhewei.com" rel="external nofollow noopener" target="_blank">Zhewei Wei</a> </div> <div class="periodical"> <em>In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/ODSS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/ODSS_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>We study the fundamental problem of sampling independent events, called subset sampling. Specifically, consider a set of n distinct events S=x1, …, xn, in which each event xi has an associated probability p(xi). The subset sampling problem aims to sample a subset T ⊆ S, such that every xi is independently included in T with probability p(xi). A naive solution is to flip a coin for each event, which takes O(n) time. However, an ideal solution is a data structure that allows drawing a subset sample in time proportional to the expected output size μ=∑i=1n p(xi), which can be significantly smaller than n in many applications. The subset sampling problem serves as an important building block in many tasks and has been the subject of various research for more than a decade.However, the majority of existing subset sampling methods are designed for a static setting, where the events in set S or their associated probabilities remain unchanged over time. These algorithms incur either large query time or update time in a dynamic setting despite the ubiquitous time-evolving events with varying probabilities in real life. Therefore, it is a pressing need, but still, an open problem, to design efficient dynamic subset sampling algorithms.In this paper, we propose ODSS, the first optimal dynamic subset sampling algorithm. The expected query time and update time of ODSS are both optimal, matching the lower bounds of the subset sampling problem. We present a nontrivial theoretical analysis to demonstrate the superiority of ODSS. We also conduct comprehensive experiments to empirically evaluate the performance of ODSS. Moreover, we apply ODSS to a concrete application: Influence Maximization. We empirically show that our ODSS can improve the complexities of existing Influence Maximization algorithms on large real-world evolving social networks.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">J-CRAD 2024</abbr> </div> <div id="2024-40148" class="col-sm-8"> <div class="title"><a href="https://crad.ict.ac.cn/en/article/doi/10.7544/issn1000-1239.202440148" rel="external nofollow noopener" target="_blank">Random-Walk Probability Computation on Dynamic Weighted Graphs</a></div> <div class="author"> Wang Hanzhi , Yi Lu , Wei Zhewei , Gan Junhao , Yuan Ye , Wen Jirong , and Du Xiaoyong </div> <div class="periodical"> <em>Journal of Computer Research and Development</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/CoinFlipWalk.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p></p> <p>Computing random-walk probabilities on graphs is the subject of extensive research in both graph theory and data mining research. However, existing work mainly focuses on static graphs, and cannot efficiently support dynamic weighted graphs, which are ubiquitous in real-world applications. We study the problem of computing random-walk probabilities on dynamic weighted graphs. We propose to use a sampling schema called coin flip sampling, rather than the more commonly adopted weighted sampling schema, for simulating random walks in dynamic weighted graphs. We demonstrate that simulations based on coin-flip sampling maintain the unbiasedness of the resulting random-walk probability approximations. Moreover, this approach allows us to simultaneously achieve a near-optimal query time complexity and an optimal O\left(1\right) update time overhead per edge insertion or deletion. This is a significant improvement over existing methods, which typically incur substantial sampling costs or rely on intricate auxiliary structures that are hard to maintain in a dynamic setting. We present both theoretical analysis and empirical evaluations to substantiate the superiority of our method on dynamic weighted graphs.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Lu Yi. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: February 13, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>